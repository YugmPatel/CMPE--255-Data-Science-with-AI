{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugdqCSM6s_aj"
      },
      "source": [
        "# House Prices Prediction Project using CRISP-DM Methodology\n",
        "This notebook follows the CRISP-DM methodology for predicting house prices using the Kaggle house prices dataset.\n",
        "We will cover the following phases: Business Understanding, Data Understanding, Data Preparation, Modeling, Evaluation, and Deployment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTrkmLTWs_ak"
      },
      "source": [
        "## Phase 1: Business Understanding\n",
        "The goal of this project is to predict house prices based on various features in the dataset. Our key objectives are:\n",
        "- Predict house prices\n",
        "- Identify the most important features\n",
        "- Improve decision-making for real estate professionals."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTXxu7Gis_ak"
      },
      "source": [
        "## Phase 2: Data Understanding\n",
        "Let's start by loading and inspecting the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXaGT9MKs_ak"
      },
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "# Load the dataset\n",
        "file_path = '/content/house prices dataset.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "# Check the size of the dataset\n",
        "print('Dataset shape:', df.shape)\n",
        "# Display the first few rows of the dataset\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MZHroIms_al"
      },
      "source": [
        "### Data Quality Assessment\n",
        "Now, let's check for missing values, duplicated rows, and outliers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fyq5WsmCs_al"
      },
      "source": [
        "# Check for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "print('Missing values per column:\n",
        "', missing_values)\n",
        "# Check for duplicate rows\n",
        "duplicate_rows = df.duplicated().sum()\n",
        "print('Number of duplicate rows:', duplicate_rows)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgHts8Qas_al"
      },
      "source": [
        "## Phase 3: Data Preparation\n",
        "We'll clean the data, handle missing values, select features, and preprocess the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AHDQyKys_am"
      },
      "source": [
        "# Drop columns with more than 30% missing values\n",
        "threshold = len(df) * 0.3\n",
        "df_cleaned = df.dropna(thresh=threshold, axis=1)\n",
        "# Fill missing numerical values with median\n",
        "numerical_columns = df_cleaned.select_dtypes(include=['float64', 'int64']).columns\n",
        "df_cleaned[numerical_columns] = df_cleaned[numerical_columns].fillna(df_cleaned[numerical_columns].median())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA8WdsBAs_am"
      },
      "source": [
        "## Phase 4: Modeling\n",
        "We'll start with a baseline Linear Regression model and then move to more advanced models like Random Forest and XGBoost."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnkdweVCs_am"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Split data into features (X) and target (y)\n",
        "X = df_cleaned.drop('SalePrice', axis=1)\n",
        "y = df_cleaned['SalePrice']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Linear Regression model\n",
        "lin_reg = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "lin_reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = lin_reg.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = mse ** 0.5\n",
        "print(f'Baseline Linear Regression RMSE: {rmse:.2f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM2iza2-s_am"
      },
      "source": [
        "## Phase 5: Evaluation\n",
        "Let's evaluate the models using additional metrics such as MAE and R²."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXxz77ZLs_am"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "# Calculate MAE and R²\n",
        "mae_lin = mean_absolute_error(y_test, y_pred)\n",
        "r2_lin = r2_score(y_test, y_pred)\n",
        "print(f'Linear Regression - MAE: {mae_lin:.2f}, R²: {r2_lin:.2f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGiyhejIs_am"
      },
      "source": [
        "## Phase 6: Deployment\n",
        "We summarize our findings and discuss potential next steps."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}